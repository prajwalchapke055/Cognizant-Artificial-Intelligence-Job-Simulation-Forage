{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4: Machine Learning Production"
      ],
      "metadata": {
        "id": "--5lnV0B8Yk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgJPWUsc770f"
      },
      "outputs": [],
      "source": [
        "#Import all libraries\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset\n",
        "def load_csv_dataset(file_path):\n",
        "    \"\"\"\n",
        "    This function takes a path string to a CSV file and loads it into a Pandas Dataframe.\n",
        "\n",
        "    Args:\n",
        "        file_path(str): The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        df: pd.Dataframe\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(f\"{path}\"\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "7HWvWMgp8D9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create target variable and predictor variables\n",
        "def create_target_predictors(\n",
        "    data: pd.Dataframe = None,\n",
        "    target: str = \"estimated_stock_pct\" ):\n",
        "    \"\"\"\n",
        "    This function takes in a Pandas Dataframe and splits the columns into a target column and a set of predictor variables.\n",
        "    This split will be used to train a supervised machine learning model.\n",
        "\n",
        "    Args:\n",
        "        data (pd.Dataframe): The input dataset.\n",
        "        target (str): The name of the variable you want to predict.\n",
        "\n",
        "    Returns:\n",
        "        X (pd.Dataframe): Predictor variables.\n",
        "        y (pd.Series): Target variable.\n",
        "     \"\"\"\n",
        "    X = data.drop(columns=[\"estimated_stock_pct\"])\n",
        "    y = data[\"estimated_stock_pct\"]\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "L5kNMn-H8FlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train algorithm\n",
        "def train_algorithm_with_cross_validation(\n",
        "    X: pd.Dataframe = None,\n",
        "    y: pd.Series = None):\n",
        "    \"\"\"\n",
        "    This function takes the predictor and target variables and\n",
        "    trains a Random Forest Regressor model across K folds. Using\n",
        "    cross-validation, performance metrics will be output for each\n",
        "    fold during training.\n",
        "\n",
        "    Args:\n",
        "        X (pd.Dataframe): Predictor variables.\n",
        "        y (pd.Series): Target variable.\n",
        "\n",
        "    Return\n",
        "    \"\"\"\n",
        "\n",
        "    #Create a list that will store the accuracies of each fold\n",
        "    accuracy = []\n",
        "\n",
        "    # Enter a loop to run K folds of cross-validation\n",
        "    for fold in range(0, K):\n",
        "\n",
        "        # Instantiate algorithm and scaler\n",
        "        model = RandomForestRegressor()\n",
        "        scaler = StandardScaler()\n",
        "\n",
        "        # Create training and test samples\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=split, random_state=42)\n",
        "\n",
        "        # Scale X data, we scale the data because it helps the algorithm to converge\n",
        "        # and helps the algorithm to not be greedy with large values\n",
        "        scaler.fit(X_train)\n",
        "        X_train = scaler.transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Train model\n",
        "        trained_model = model.fit(X_train, y_train)\n",
        "\n",
        "        # Generate predictions on test sample\n",
        "        y_pred = trained_model.predict(X_test)\n",
        "\n",
        "        # Compute accuracy using mean absolute error\n",
        "        mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)\n",
        "        accuracy.append(mae)\n",
        "        print(f\"Fold {fold + 1}: MAE = {mae:.3f}\")\n",
        "\n",
        "    # Compute the average MAE across all folds\n",
        "    avg_mae = sum(accuracy) / len(accuracy)\n",
        "    print(f\"Average MAE: {avg_mae:.2f}\")\n",
        "    return avg_mae"
      ],
      "metadata": {
        "id": "5J9D3mPr8IIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}